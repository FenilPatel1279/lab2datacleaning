{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c6e9c30",
   "metadata": {},
   "source": [
    "# Name: Fenil Patel\n",
    "## Subjet: Machine learning Programming\n",
    "\n",
    "\n",
    "#### Lab2 - Data Collection and Pre-processing\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd2ae26",
   "metadata": {},
   "source": [
    "## Step 1: Hello Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd347784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Option 1: Use raw string with r prefix\n",
    "file_path = r\"D:\\Applied AI & ML\\Machine Learning Porgramming\\Labs\\ecommerce_500_rows (1).csv\"\n",
    "\n",
    "# Option 2: Use double backslashes (\\\\)\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50248fae",
   "metadata": {},
   "source": [
    "## Step 2: Pick the Right Container\n",
    "\n",
    "Since it enables the encapsulation of both data and functionality (such as clean/total functions), a class is the ideal containment for transaction information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58be6218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load transaction data from a CSV file and convert each row into a Transaction object\n",
    "def load_transactions(path: str) -> list[Transaction]:\n",
    "    # Read the first 500 rows from the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(path).head(500)\n",
    "\n",
    "    # Use a list comprehension to create a list of Transaction objects from each row\n",
    "    transactions = [\n",
    "        Transaction(\n",
    "            row['Order Date'],                    # Extract order date\n",
    "            row['Customer ID'],                   # Extract customer ID\n",
    "            row['Product'],                       # Extract product name\n",
    "            float(row['Unit Price']),             # Convert unit price to float\n",
    "            int(row['Quantity']),                 # Convert quantity to integer\n",
    "            row.get('Coupon Code', None),         # Get coupon code if available; otherwise, use None\n",
    "            row['City']                           # Extract shipping city\n",
    "        )\n",
    "        for _, row in df.iterrows()               # Loop through each row of the DataFrame\n",
    "    ]\n",
    "\n",
    "    # Return the list of Transaction objects\n",
    "    return transactions\n",
    "\n",
    "# Load transactions from the specified file path\n",
    "transactions = load_transactions(\"D:\\\\Applied AI & ML\\\\Machine Learning Porgramming\\\\Labs\\\\ecommerce_500_rows (1).csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248bab04",
   "metadata": {},
   "source": [
    "# Step 3: Transaction class OOP Data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a649cd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "from datetime import datetime\n",
    "\n",
    "# This class represents a single e-commerce transaction with fields for all important info.\n",
    "@dataclass\n",
    "class Transaction:\n",
    "    date: str               # The date when the transaction occurred\n",
    "    customer_id: str        # Unique ID of the customer\n",
    "    product: str            # Name of the product purchased\n",
    "    price: float            # Price of a single unit of the product\n",
    "    quantity: int           # Number of units purchased\n",
    "    coupon_code: Optional[str]  # Optional discount code applied to the order\n",
    "    shipping_city: str      # City where the order is being shipped\n",
    "\n",
    "    # This method checks and fixes bad data in the price field.\n",
    "    def clean(self):\n",
    "        # If the price is missing or marked as \"N/A\", treat it as 0.0\n",
    "        if isinstance(self.price, str) and self.price == \"N/A\":\n",
    "            self.price = 0.0\n",
    "        # If the price is accidentally entered as negative, flip it to positive\n",
    "        if self.price < 0:\n",
    "            self.price = abs(self.price)\n",
    "\n",
    "    # This method calculates the total order amount (price Ã— quantity)\n",
    "    def total(self):\n",
    "        return self.price * self.quantity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df720e76",
   "metadata": {},
   "source": [
    "# Step 4: Bulk load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64968d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transactions(path: str) -> list[Transaction]:\n",
    "    \n",
    "    # Load up to 500 rows from a CSV file and turn each row into a Transaction object.\n",
    "    \n",
    "    df = pd.read_csv(path).head(500)\n",
    "    \n",
    "    # Convert each row into a Transaction:\n",
    "    transactions = []\n",
    "    for _, row in df.iterrows():\n",
    "        tx = Transaction(\n",
    "            row['Order Date'],              # when the order was placed\n",
    "            row['Customer ID'],             # who placed the order\n",
    "            row['Product'],                 # what they bought\n",
    "            float(row['Unit Price']),       # cost per item\n",
    "            int(row['Quantity']),           # number of items\n",
    "            row.get('Coupon Code', None),   # any coupon they used (or None)\n",
    "            row['City']                     # shipping destination\n",
    "        )\n",
    "        transactions.append(tx)\n",
    "    \n",
    "    # Return the full list of Transaction objects\n",
    "    return transactions\n",
    "\n",
    "transactions = load_transactions(\n",
    "    r\"D:\\Applied AI & ML\\Machine Learning Porgramming\\Labs\\ecommerce_500_rows (1).csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d0f429",
   "metadata": {},
   "source": [
    "# Step 5: Quick profiling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c77fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transactions list from df if not already created\n",
    "transactions = [\n",
    "    Transaction(\n",
    "        date=row['Order Date'],\n",
    "        customer_id=row['Customer ID'],\n",
    "        product=row['Product'],\n",
    "        price=row['Unit Price'],\n",
    "        quantity=row['Quantity'],\n",
    "        coupon_code=row['Coupon Code'],\n",
    "        shipping_city=row['City']\n",
    "    )\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "\n",
    "# Extract prices and cities\n",
    "prices = [t.price for t in transactions]\n",
    "cities = set(t.shipping_city for t in transactions)\n",
    "\n",
    "# Calculate basic stats\n",
    "min_price = min(prices)\n",
    "mean_price = sum(prices) / len(prices)\n",
    "max_price = max(prices)\n",
    "unique_city_count = len(cities)\n",
    "\n",
    "# Print output nicely\n",
    "print(\"Price Summary\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Minimum Price  : ${min_price:,.2f}\")\n",
    "print(f\"Average Price  : ${mean_price:,.2f}\")\n",
    "print(f\"Maximum Price  : ${max_price:,.2f}\")\n",
    "print()\n",
    "print(\" Shipping Cities\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Number of Unique Cities: {unique_city_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b091359a",
   "metadata": {},
   "source": [
    "## Step 6: Spot the Grime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3e4a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions[10].price = -99.99\n",
    "transactions[20].coupon_code = \"N/A\"\n",
    "transactions[30].price = \"N/A\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d16bad7",
   "metadata": {},
   "source": [
    "## Step 7: Cleaning \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43c32fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before cleaning\n",
    "dirty_before = [t for t in transactions if isinstance(t.price, str) or t.price < 0]\n",
    "print(\"Dirty before:\", len(dirty_before))\n",
    "\n",
    "# Clean all\n",
    "for t in transactions:\n",
    "    t.clean()\n",
    "\n",
    "# After cleaning\n",
    "dirty_after = [t for t in transactions if isinstance(t.price, str) or t.price < 0]\n",
    "print(\"Dirty after:\", len(dirty_after))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f8bd4b",
   "metadata": {},
   "source": [
    "## Step 8: Transformations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1edb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_coupon(code):\n",
    "    # Check if the code exists and starts with the word \"SAVE\"\n",
    "    if code and str(code).startswith(\"SAVE\"):\n",
    "        # Extract the number after \"SAVE\" and convert it to an integer\n",
    "        return int(code[4:])\n",
    "    return 0\n",
    "\n",
    "# Go through each transaction and assign a discount based on the coupon code\n",
    "for t in transactions:\n",
    "    t.discount = parse_coupon(t.coupon_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb27db64",
   "metadata": {},
   "source": [
    "## Step 9: Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29edaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Loop through each transaction object in the list\n",
    "for t in transactions:\n",
    "    # Calculate how many days have passed since the purchase date\n",
    "    t.days_since_purchase = (\n",
    "        datetime.now() - datetime.strptime(t.date, \"%m/%d/%Y\")\n",
    "    ).days  # Convert the date string to a datetime object and subtract from today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e5c606",
   "metadata": {},
   "source": [
    "## Step 10: Mini-Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa7a0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute city revenue if not already defined\n",
    "df['Revenue'] = df['Unit Price'] * df['Quantity']\n",
    "city_revenue = df.groupby('City')['Revenue'].sum().reset_index()\n",
    "\n",
    "print(city_revenue)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5e23b3",
   "metadata": {},
   "source": [
    "## Step 11: Serialization Checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d0b6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Turn each Transaction into a simple dict of its fields\n",
    "json_data = [t.__dict__ for t in transactions]\n",
    "\n",
    "# Save all transactions to a human-readable JSON file\n",
    "with open(\"cleaned_data.json\", \"w\") as f:\n",
    "    json.dump(json_data, f, indent=2)  # indent=2 makes it easy to read\n",
    "\n",
    "# Now, load that same data into a pandas DataFrame\n",
    "df = pd.DataFrame(json_data)\n",
    "\n",
    "# Convert the DataFrame into an Apache Arrow table\n",
    "table = pa.Table.from_pandas(df)\n",
    "\n",
    "# Write the Arrow table out as a Parquet file for fast, compact storage\n",
    "pq.write_table(table, \"cleaned_data.parquet\")\n",
    "# Read the Parquet file back into a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e153107",
   "metadata": {},
   "source": [
    "## Step 12: Soft Interview Reflection\n",
    "OOP helped encapsulate logic cleanly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae5edbe",
   "metadata": {},
   "source": [
    "Combining functionality and data was made simpler by object-oriented programming.  Code became scalable and accessible by enclosing functionality such as `.clean()` and `.total()` inside `Transaction`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f00e03",
   "metadata": {},
   "source": [
    "# Data-Dictionary Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3782f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your datasets\n",
    "# Replace this with the actual file path to your primary CSV file\n",
    "file_path = r\"D:\\Applied AI & ML\\Machine Learning Porgramming\\Labs\\ecommerce_500_rows (1).csv\"\n",
    "\n",
    "# Load the transaction data (primary)\n",
    "primary_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the metadata we created earlier (secondary)\n",
    "secondary_df = pd.read_csv(r\"D:\\Applied AI & ML\\Machine Learning Porgramming\\Labs\\secondary_metadata.csv\")\n",
    "\n",
    "# Manually create a list of dictionaries that describe each column\n",
    "# We'll include the column name, its type, a short description, and the source of the data\n",
    "data_dictionary = [\n",
    "    {\"Field\": \"Order Date\", \"Type\": \"string\", \"Description\": \"When the order was placed\", \"Source\": \"Primary CSV\"},\n",
    "    {\"Field\": \"Customer ID\", \"Type\": \"string\", \"Description\": \"A unique ID for the customer\", \"Source\": \"Primary CSV\"},\n",
    "    {\"Field\": \"Product\", \"Type\": \"string\", \"Description\": \"The product that was purchased\", \"Source\": \"Primary CSV\"},\n",
    "    {\"Field\": \"Unit Price\", \"Type\": \"float\", \"Description\": \"Price of a single unit\", \"Source\": \"Primary CSV\"},\n",
    "    {\"Field\": \"Quantity\", \"Type\": \"int\", \"Description\": \"Number of units bought\", \"Source\": \"Primary CSV\"},\n",
    "    {\"Field\": \"Coupon Code\", \"Type\": \"string\", \"Description\": \"Any discount coupon applied\", \"Source\": \"Primary CSV\"},\n",
    "    {\"Field\": \"City\", \"Type\": \"string\", \"Description\": \"City where the item was shipped\", \"Source\": \"Primary CSV\"},\n",
    "    \n",
    "    {\"Field\": \"Product_ID\", \"Type\": \"string\", \"Description\": \"Internal product ID\", \"Source\": \"Secondary Metadata\"},\n",
    "    {\"Field\": \"Category\", \"Type\": \"string\", \"Description\": \"The category the product belongs to\", \"Source\": \"Secondary Metadata\"},\n",
    "    {\"Field\": \"Brand\", \"Type\": \"string\", \"Description\": \"Product's brand name\", \"Source\": \"Secondary Metadata\"},\n",
    "    {\"Field\": \"Province\", \"Type\": \"string\", \"Description\": \"Province of the shipping city\", \"Source\": \"Secondary Metadata\"},\n",
    "    {\"Field\": \"Country\", \"Type\": \"string\", \"Description\": \"Country of the shipping city\", \"Source\": \"Secondary Metadata\"},\n",
    "    {\"Field\": \"Population\", \"Type\": \"int\", \"Description\": \"Population of the shipping city\", \"Source\": \"Secondary Metadata\"},\n",
    "    {\"Field\": \"Coupon_Description\", \"Type\": \"string\", \"Description\": \"Explanation of the coupon offer\", \"Source\": \"Secondary Metadata\"},\n",
    "    {\"Field\": \"Discount_Percent\", \"Type\": \"int\", \"Description\": \"Percentage of discount offered\", \"Source\": \"Secondary Metadata\"},\n",
    "    {\"Field\": \"Coupon_Expiry\", \"Type\": \"string\", \"Description\": \"Expiry date of the coupon\", \"Source\": \"Secondary Metadata\"},\n",
    "]\n",
    "\n",
    "# Convert this list into a DataFrame so it's easy to view or export\n",
    "dictionary_df = pd.DataFrame(data_dictionary)\n",
    "\n",
    "# Show the data dictionary\n",
    "dictionary_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
